<!DOCTYPE HTML>
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

<!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=G-H6N57KJW91"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());
  gtag('config', 'G-H6N57KJW91');
</script>

  <title>Jathushan Rajasegaran</title>
  
  <meta name="author" content="Jathushan Rajasegaran">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  
  <link rel="stylesheet" type="text/css" href="stylesheet.css">
  <link rel="icon" type="image/gif" href="images/icon.gif">
</head>

<!-- PhD student at <a href="https://bair.berkeley.edu/">BAIR</a> 

-->
<body>
  <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    <tr style="padding:0px">
      <td style="padding:0px">
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr style="padding:0px">
            <td style="padding:2.5%;width:63%;vertical-align:middle">
              <p style="text-align:center">
                <name>Jathushan Rajasegaran</name>
              </p>
              <p>I am a Ph.D. student at <a href="https://bair.berkeley.edu/">BAIR</a> advised by Prof. <a href="http://people.eecs.berkeley.edu/~malik/">Jitendra Malik</a>. 

				I am broadly interested in Computer Vision and Deep Learning, with a focus on developing models for understanding long videos. 
				I completed my undergraduate study at University of Moratuwa, with a major in Electronic and Telecommunication Engineering. 
				My Bachelor's Thesis was advised by Dr. Ranga Rodigo.

              </p>
              <!-- <p>
                At Google I've worked on <a href="https://ai.googleblog.com/2020/12/portrait-light-enhancing-portrait.html">Portrait Light</a>, <a href="https://ai.googleblog.com/2014/04/lens-blur-in-new-google-camera-app.html">Lens Blur</a>, <a href="https://ai.googleblog.com/2014/10/hdr-low-light-and-high-dynamic-range.html">HDR+</a>, <a href="https://www.google.com/get/cardboard/jump/">Jump</a>, <a href="https://ai.googleblog.com/2017/10/portrait-mode-on-pixel-2-and-pixel-2-xl.html">Portrait Mode</a>, and <a href="https://www.youtube.com/watch?v=JSnB06um5r4">Glass</a>. I did my PhD at <a href="http://www.eecs.berkeley.edu/">UC Berkeley</a>, where I was advised by <a href="http://www.cs.berkeley.edu/~malik/">Jitendra Malik</a> and funded by the <a href="http://www.nsfgrfp.org/">NSF GRFP</a>. I did my bachelors at the <a href="http://cs.toronto.edu">University of Toronto</a>.
                I've received the <a href="https://www2.eecs.berkeley.edu/Students/Awards/15/">C.V. Ramamoorthy Distinguished Research Award</a> and the <a href="https://www.thecvf.com/?page_id=413#YRA">PAMI Young Researcher Award</a>.
              </p> -->
              <p style="text-align:center">
                <a href="mailto:brjathu@gmail.com">Email</a> &nbsp/&nbsp
                <!-- <a href="data/Jathushan-CV.pdf">CV</a> &nbsp/&nbsp -->
                <a href="bio.html">Bio</a> &nbsp/&nbsp
                <a href="https://scholar.google.com/citations?user=Ctp3igcAAAAJ&hl=en">Google Scholar</a> &nbsp/&nbsp
                <!-- <a href="https://twitter.com/jon_barron">Twitter</a> &nbsp/&nbsp -->
                <a href="https://github.com/brjathu/">Github</a>
              </p>
            </td>
            <td style="padding:2.5%;width:40%;max-width:40%">
              <a href="images/Jathushan.JPG"><img style="width:100%;max-width:100%" alt="profile photo" src="images/Jathushan_circle.png" class="hoverZoomLink"></a>
            </td>
          </tr>
        </tbody></table>


        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>Research</heading>
              <p>
                My research interests lie in the general area of computer vision and deep learning, 
				particularly in long-term video understanding, deep neural architectures and meta/continual learning. Representative papers are <span class="highlight">highlighted</span>.               
              </p>
            </td>
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>







<tr onmouseout="itaml_animation_stop()" onmouseover="itaml_animation_start()"  bgcolor="#ffffd0" > 
	<td style="padding:20px;width:25%;vertical-align:middle">
		<div class="one">
			<div class="two" id='itaml_image'>
				<img src='images/itaml_gif.gif' width="160"></div>
			<img src='images/itaml_png.png' width="160"></div>
		<script type="text/javascript">function itaml_animation_start() {document.getElementById('itaml_image').style.opacity = "1";}
			function itaml_animation_stop() {document.getElementById('itaml_image').style.opacity = "0";}itaml_animation_stop()
		</script>
	</td>
	<td style="padding:20px;width:75%;vertical-align:middle">
		<a href="https://openaccess.thecvf.com/content_CVPR_2020/html/Rajasegaran_iTAML_An_Incremental_Task-Agnostic_Meta-learning_Approach_CVPR_2020_paper.html">
			<papertitle>iTAML: An Incremental Task-Agnostic Meta-learning Approach.</papertitle></a><br>	
		<strong>Jathushan Rajasegaran</strong>,				
		<a href="https://salman-h-khan.github.io/">Salman Khan</a>, 
		<a href="https://mhayat.netlify.app/">Munawar Hayat</a>, <br>
		<a href="https://sites.google.com/view/fahadkhans/home">Fahad Shahbaz Khan</a>,
		<br>
		<em>CVPR</em>, 2020 
		<br>
		<a href="https://openaccess.thecvf.com/content_CVPR_2020/html/Rajasegaran_iTAML_An_Incremental_Task-Agnostic_Meta-learning_Approach_CVPR_2020_paper.html">paper</a>/
		<a href="https://arxiv.org/abs/2003.11652">arxiv</a>/
		<a href="data/CVPR2020_slides.pdf">slides</a>/
		<a href="data/CVPR2020_1min.mp4">video</a>/
		<a href="https://github.com/brjathu/iTAML">code</a>
		<p></p>
		<p>By learning generic represenatations from past tasks, we can easily adapt to new tasks as well as remember old tasks.</p>
	</td>
</tr>





<tr onmouseout="rps_animation_stop()" onmouseover="rps_animation_start()"  bgcolor="#ffffd0" > 
	<td style="padding:20px;width:25%;vertical-align:middle">
		<div class="one">
			<div class="two" id='rps_image'>
				<img src='images/rps_gif.gif' width="160"></div>
			<img src='images/rps_png.png' width="160"></div>
		<script type="text/javascript">function rps_animation_start() {document.getElementById('rps_image').style.opacity = "1";}
			function rps_animation_stop() {document.getElementById('rps_image').style.opacity = "0";}rps_animation_stop()
		</script>
	</td>
	<td style="padding:20px;width:75%;vertical-align:middle">
		<a href="https://papers.nips.cc/paper/2019/hash/83da7c539e1ab4e759623c38d8737e9e-Abstract.html">
			<papertitle>Random Path Selection for Incremental Learning.</papertitle></a><br>	
		<strong>Jathushan Rajasegaran</strong>,				
		<a href="https://mhayat.netlify.app/">Munawar Hayat</a>,
		<a href="https://salman-h-khan.github.io/">Salman Khan</a>,  <br>
		<a href="https://sites.google.com/view/fahadkhans/home">Fahad Shahbaz Khan</a>,
		<a href="http://www.inceptioniai.org/">Ling Shao</a>,
		<br>
		<em>NeurIPS</em>, 2019 
		<br>
		<a href="https://papers.nips.cc/paper/2019/hash/83da7c539e1ab4e759623c38d8737e9e-Abstract.html">paper</a>/
		<a href="https://arxiv.org/pdf/1906.01120.pdf">arxiv</a>/
		<a href="data/NeurIPS2019_Poster.pdf">poster</a>/
		<a href="https://github.com/brjathu/rps">code</a>
		<p></p>
		<p>We increase the width of a ResNet like model by adding extra skip connections when new tasks are introduced.</p>
	</td>
</tr>





<tr onmouseout="deepcaps_animation_stop()" onmouseover="deepcaps_animation_start()" bgcolor="#ffffd0" >  
	<td style="padding:20px;width:25%;vertical-align:middle">
		<div class="one">
			<div class="two" id='deepcaps_image'>
				<img src='images/deepcaps_gif.gif' width="160"></div>
			<img src='images/deepcaps_png.png' height="160"></div>
		<script type="text/javascript">function deepcaps_animation_start() {document.getElementById('deepcaps_image').style.opacity = "1";}
			function deepcaps_animation_stop() {document.getElementById('deepcaps_image').style.opacity = "0";}deecaps_animation_stop()
		</script>
	</td>
	<td style="padding:20px;width:75%;vertical-align:middle">
		<a href="http://openaccess.thecvf.com/content_CVPR_2019/html/Rajasegaran_DeepCaps_Going_Deeper_With_Capsule_Networks_CVPR_2019_paper.html">
			<papertitle>DeepCaps: Going Deeper with Capsule Networks</papertitle></a><br>
		<strong>Jathushan Rajasegaran</strong>,
		<a href="https://scholar.google.com/citations?user=2yTeZ58AAAAJ&hl=en">Vinoj Jayasundara</a>,
		<a href="https://scholar.google.com/citations?user=98ItndMAAAAJ&hl=en">Sandaru Jayasekara</a>, <br>
		<a href="https://scholar.google.com/citations?user=CFJHvLcAAAAJ&hl=en">Hirunima Jayasekara</a>,
		<a href="https://www.suranga.me/">Suranga Seneviratne</a>,
		<a href="https://ranga.staff.uom.lk/">Ranga Rodrigo</a>
		<br>
		<em>CVPR</em>, 2019 &nbsp <font color="red"><strong>(Oral Presentation)</strong></font>
		<br>
		<a href="http://openaccess.thecvf.com/content_CVPR_2019/html/Rajasegaran_DeepCaps_Going_Deeper_With_Capsule_Networks_CVPR_2019_paper.html">paper</a>/
		<a href="data/CVPR19_Poster.pdf">poster</a>/
		<a href="https://www.youtube.com/watch?v=PzALQZOy09c&t=3600s">video</a>/
		<a href="https://github.com/brjathu/deepcaps">code</a>
		<p></p>
		<p>Capsule Networks are cool, but they are shallow. We can increase the depth by 3D convolutions and skip connections.</p>
	</td>
</tr>






<tr onmouseout="textcaps_animation_stop()" onmouseover="textcaps_animation_start()">  
	<td style="padding:20px;width:25%;vertical-align:middle">
		<div class="one">
			<div class="two" id='textcaps_image'>
				<img src='images/textcaps_gif.gif' width="160"></div>
			<img src='images/textcaps_png.png' height="160"></div>
		<script type="text/javascript">function textcaps_animation_start() {document.getElementById('textcaps_image').style.opacity = "1";}
			function textcaps_animation_stop() {document.getElementById('textcaps_image').style.opacity = "0";}textcaps_animation_stop()
		</script>
	</td>
	<td style="padding:20px;width:75%;vertical-align:middle">
		<a href="https://ieeexplore.ieee.org/abstract/document/8658735/">
			<papertitle>TextCaps: Handwritten Character Recognition with Very Small Datasets</papertitle></a><br>
		<a href="https://scholar.google.com/citations?user=2yTeZ58AAAAJ&hl=en">Vinoj Jayasundara</a>,
		<a href="https://scholar.google.com/citations?user=98ItndMAAAAJ&hl=en">Sandaru Jayasekara</a>,
		<a href="https://scholar.google.com/citations?user=CFJHvLcAAAAJ&hl=en">Hirunima Jayasekara</a>,
		<strong>Jathushan Rajasegaran</strong>, <br>
		<a href="https://www.suranga.me/">Suranga Seneviratne</a>,
		<a href="https://ranga.staff.uom.lk/">Ranga Rodrigo</a>
		<br>
		<em>WACV</em>, 2019
		<br>
		<a href="https://ieeexplore.ieee.org/abstract/document/8658735/">paper</a>/
		<a href="https://arxiv.org/abs/1904.08095">arxiv</a>/
		<a href="data/WACV19_Poster.pdf">poster</a>/
		<a href="https://github.com/brjathu/textcaps">code</a>
		<p></p>
		<p>Capsule Networks can capture actual variations that are present in human hand writing, so we generate more data and retrain the capsule networks.</p>
	</td>
</tr>






<tr onmouseout="www_animation_stop()" onmouseover="www_animation_start()" >  
	<td style="padding:20px;width:25%;vertical-align:middle">
		<div class="one">
			<div class="two" id='www_image'>
				<img src='images/www_gif.gif' width="160"></div>
			<img src='images/www_png.png' height="160"></div>
		<script type="text/javascript">function www_animation_start() {document.getElementById('www_image').style.opacity = "1";}
			function www_animation_stop() {document.getElementById('www_image').style.opacity = "0";}www_animation_stop()
		</script>
	</td>
	<td style="padding:20px;width:75%;vertical-align:middle">
		<a href="https://dl.acm.org/doi/abs/10.1145/3308558.3313427">
			<papertitle>A Multi-modal Neural Embeddings Approach for Detecting Mobile Counterfeit Apps: A Case Study on Google Play Store</papertitle></a><br>
		<strong>Jathushan Rajasegaran</strong>, 
		<a href="https://naveenhk.github.io/">Naveen Karunanayake</a>,
		<a href="https://scholar.google.com.sg/citations?user=nELzVusAAAAJ&hl=en">Ashanie Gunathillake</a>,<br>
		<a href="https://scholar.google.com.sg/citations?user=eztAtiUAAAAJ&hl=en">Suranga Seneviratne</a>,
		<a href="https://www.suranga.me/">Guillaume Jourjon</a>,
		<br>
		<em>WWW</em>, 2019
		<br>
		<a href="https://ieeexplore.ieee.org/abstract/document/9133509">paper</a>/
		<a href="https://arxiv.org/abs/1804.09882">arxiv</a>/
		<a href="data/WWW19_Poster.pdf">poster</a>/
		<p></p>
		<p>We use content and style representations detect counterfeit apps in playstore.</p>
	</td>
</tr>


          
    
          
    
          
          
        <!-- <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20"><tbody>
          <tr>
            <td>
              <heading>Service</heading>
            </td>
          </tr>
        </tbody></table>
        <table width="100%" align="center" border="0" cellpadding="20"><tbody>
          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle"><img src="images/cvf.jpg"></td>
            <td width="75%" valign="center">
              <a href="http://cvpr2021.thecvf.com/area-chairs">Area Chair, CVPR 2021</a>
              <br><br>
              <a href="http://cvpr2019.thecvf.com/area_chairs">Area Chair, CVPR 2019</a>
              <br><br>
              <a href="http://cvpr2018.thecvf.com/organizers/area_chairs">Area Chair, CVPR 2018</a>
            </td>
          </tr>
          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/cs188.jpg" alt="cs188">
            </td>
            <td width="75%" valign="center">
              <a href="http://inst.eecs.berkeley.edu/~cs188/sp11/announcements.html">Graduate Student Instructor, CS188 Spring 2011</a>
              <br>
              <br>
              <a href="http://inst.eecs.berkeley.edu/~cs188/fa10/announcements.html">Graduate Student Instructor, CS188 Fall 2010</a>
              <br>
              <br>
              <a href="http://aima.cs.berkeley.edu/">Figures, "Artificial Intelligence: A Modern Approach", 3rd Edition</a>
            </td>
          </tr>
        </tbody></table> -->
		

		<table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
			<tbody>
				<tr>
				<td style="padding:0px">
					<br>
					<p style="text-align:right;font-size:small;">
					Website source from Jon Barron <a href="https://jonbarron.info/">here</a>
					<br>
					</p>
				</td>
				</tr>
		  	</tbody>
		</table>


      </td>
    </tr>
  </table>
</body>

</html>
